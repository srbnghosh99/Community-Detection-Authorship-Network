,paper_idx,title,author,year,conference,abstract,reference
0,53e9b44ab7602d9703f424a7,"Group formation in large social networks: membership, growth, and evolution","Lars Backstrom, Dan Huttenlocher, Jon Kleinberg, Xiangyang Lan",2006,Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,"The processes by which communities come together, attract new members, and develop over time is a central research issue in the social sciences - political movements, professional organizations, and religious denominations all provide fundamental examples of such communities. In the digital domain, on-line groups are becoming increasingly prominent due to the growth of community and social networking sites such as MySpace and LiveJournal. However, the challenge of collecting and analyzing large-scale time-resolved data on social groups and communities has left most basic questions about the evolution of such groups largely unresolved: what are the structural features that influence whether individuals will join communities, which communities will grow rapidly, and how do the overlaps among pairs of communities change over time.Here we address these questions using two large sources of data: friendship links and community membership on LiveJournal, and co-authorship and conference publications in DBLP. Both of these datasets provide explicit user-defined communities, where conferences serve as proxies for communities in DBLP. We study how the evolution of these communities relates to properties such as the structure of the underlying social networks. We find that the propensity of individuals to join communities, and of communities to grow rapidly, depends in subtle ways on the underlying network structure. For example, the tendency of an individual to join a community is influenced not just by the number of friends he or she has within the community, but also crucially by how those friends are connected to one another. We use decision-tree techniques to identify the most significant structural determinants of these properties. We also develop a novel methodology for measuring movement of individuals between communities, and show how such movements are closely aligned with changes in the topics of interest within the communities.","['53e9979fb7602d9701f6fbfd', '53e9a37ab7602d9702c883ee', '53e99845b7602d9702073c2e', '53e9b81cb7602d97043d391a', '53e99a92b7602d970230a9a8', '53e9b917b7602d9704500623', '53e9bb15b7602d9704750d5a', '53e9a066b7602d9702949aea', '53e9b6d1b7602d970425d749', '53e99c28b7602d97024d4c01', '53e99f7fb7602d9702851ebd', '53e9b500b7602d970402eba1', '53e9a3edb7602d9702d06f4c', '53e9b5a8b7602d97040ede83', '53e9b239b7602d9703cd3f2d']"
1,53e9994cb7602d9702189bf8,Beyond myopic inference in big data pipelines,"Karthik Raman, Adith Swaminathan, Johannes Gehrke, Thorsten Joachims",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"Big Data Pipelines decompose complex analyses of large data sets into a series of simpler tasks, with independently tuned components for each task. This modular setup allows re-use of components across several different pipelines. However, the interaction of independently tuned pipeline components yields poor end-to-end performance as errors introduced by one component cascade through the whole pipeline, affecting overall accuracy. We propose a novel model for reasoning across components of Big Data Pipelines in a probabilistically well-founded manner. Our key idea is to view the interaction of components as dependencies on an underlying graphical model. Different message passing schemes on this graphical model provide various inference algorithms to trade-off end-to-end performance and computational cost. We instantiate our framework with an efficient beam search algorithm, and demonstrate its efficiency on two Big Data Pipelines: parsing and relation extraction.","['53e99fa9b7602d9702880579', '53e9ae6fb7602d97038898a1', '53e9a091b7602d9702976478', '53e9bd3eb7602d97049c9b9e', '53e9bcb3b7602d9704933f53', '53e9b903b7602d97044e8650', '53e9ae29b7602d970383b8f3', '53e9af67b7602d97039a7412', '53e9a533b7602d9702e58345', '53e99b94b7602d970243a178', '53e9aa23b7602d970338fc4b', '53e9bc32b7602d97048a43da', '53e9baf2b7602d970472520b', '53e9b8e8b7602d97044c9035', '53e998dbb7602d97021161b1']"
2,53e9ab9eb7602d9703546fcf,Diversity maximization under matroid constraints,"Zeinab Abbassi, Vahab S. Mirrokni, Mayur Thakur",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"Aggregator websites typically present documents in the form of representative clusters. In order for users to get a broader perspective, it is important to deliver a diversified set of representative documents in those clusters. One approach to diversification is to maximize the average dissimilarity among documents. Another way to capture diversity is to avoid showing several documents from the same category (e.g. from the same news channel). We combine the above two diversification concepts by modeling the latter approach as a (partition) matroid constraint, and study diversity maximization problems under matroid constraints. We present the first constant-factor approximation algorithm for this problem, using a new technique. Our local search 0.5-approximation algorithm is also the first constant-factor approximation for the max-dispersion problem under matroid constraints. Our combinatorial proof technique for maximizing diversity under matroid constraints uses the existence of a family of Latin squares which may also be of independent interest. In order to apply these diversity maximization algorithms in the context of aggregator websites and as a preprocessing step for our diversity maximization tool, we develop greedy clustering algorithms that maximize weighted coverage of a predefined set of topics. Our algorithms are based on computing a set of cluster centers, where clusters are formed around them. We show the better performance of our algorithms for diversity and coverage maximization by running experiments on real (Twitter) and synthetic data in the context of real-time search over micro-posts. Finally we perform a user study validating our algorithms and diversity metrics.","['53e9a69fb7602d9702fd18dc', '53e9b180b7602d9703c068be', '53e9b7f5b7602d97043a4573', '53e9a8d4b7602d9703226366', '53e9a82bb7602d970317170b', '53e9b648b7602d97041a894a', '53e9b1bcb7602d9703c48cb1', '53e9b724b7602d97042b91d3', '53e99e79b7602d9702740221', '53e9ada5b7602d970379fa3a', '53e9bbbcb7602d9704807344', '53e9a1c3b7602d9702abc477', '53e99c1ab7602d97024c9caf', '53e99b04b7602d970239152d', '53e9afa0b7602d97039ea981', '53e99ab8b7602d97023329c3', '53e9a131b7602d9702a23a99', '53e99a2fb7602d970228d6fa', '53e99b21b7602d97023b4c57', '53e9aefbb7602d970392dad3', '53e9ab20b7602d97034a5a8a', '53e99a2ab7602d9702283e05', '53e9ac42b7602d970360e206']"
3,53e9a2fab7602d9702c05803,Personalized diagnosis for over-constrained problems,"Alexander Felfernig, Monika Schubert, Stefan Reiterer",2013,Graz,"Constraint-based applications such as configurators, recommenders, and scheduling systems support users in complex decision making scenarios. Typically, these systems try to identify a solution that satisfies all articulated user requirements. If the requirements are inconsistent with the underlying constraint set, users have to be actively supported in finding a way out from the no solution could be found dilemma. In this paper we introduce techniques that support the calculation of personalized diagnoses for inconsistent constraint sets. These techniques significantly improve the diagnosis prediction quality compared to approaches based on the calculation of minimal cardinality diagnoses. In order to show the applicability of our approach we present the results of an empirical study and a corresponding performance analysis.","['53e9bbcfb7602d970481e7f2', '53e9a2b2b7602d9702bba4e2', '53e999ffb7602d970224a173', '53e9b403b7602d9703ef6df0', '53e9bb94b7602d97047de6d3', '53e9a81fb7602d970316536d', '53e9a95eb7602d97032b9dd8', '53e9a667b7602d9702f9a5b9', '53e99e4db7602d97027143b9']"
4,53e9ab55b7602d97034e76d5,"Reliability of Interactive Computer Exhibits or, Why Doesn't This @#!!#& Thing Work?",Jim Oker,1991,ICHIM,"Constraint-based applications such as configurators, recommenders, and scheduling systems support users in complex decision making scenarios. Typically, these systems try to identify a solution that satisfies all articulated user requirements. If the requirements are inconsistent with the underlying constraint set, users have to be actively supported in finding a way out from the no solution could be found dilemma. In this paper we introduce techniques that support the calculation of personalized diagnoses for inconsistent constraint sets. These techniques significantly improve the diagnosis prediction quality compared to approaches based on the calculation of minimal cardinality diagnoses. In order to show the applicability of our approach we present the results of an empirical study and a corresponding performance analysis.",[]
5,53e9b0a5b7602d9703b11186,Connecting users across social media sites: a behavioral-modeling approach,"Reza Zafarani, Huan Liu",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"People use various social media for different purposes. The information on an individual site is often incomplete. When sources of complementary information are integrated, a better profile of a user can be built to improve online services such as verifying online information. To integrate these sources of information, it is necessary to identify individuals across social media sites. This paper aims to address the cross-media user identification problem. We introduce a methodology (MOBIUS) for finding a mapping among identities of individuals across social media sites. It consists of three key components: the first component identifies users' unique behavioral patterns that lead to information redundancies across sites; the second component constructs features that exploit information redundancies due to these behavioral patterns; and the third component employs machine learning for effective user identification. We formally define the cross-media user identification problem and show that MOBIUS is effective in identifying users across social media sites. This study paves the way for analysis and mining across social media sites, and facilitates the creation of novel online services across sites.","['53e9b91eb7602d970450741d', '53e99b7eb7602d970242335d', '53e9b693b7602d9704205083', '53e9a423b7602d9702d3e697', '53e99cf5b7602d97025ab0c6', '53e9b532b7602d970406be18', '53e9bc96b7602d97049170fb', '53e997e9b7602d9701fe3fe1']"
6,555043af45ce0a409eb48d40,Extraction possibiliste de concepts MeSH à partir de documents biomédicaux.,"Wiem Chebil, Lina Fatima Soualmia, Mohamed N. Omri, Stéfan Jacques Darmoni",2014,Revue d'Intelligence Artificielle,"We propose in this paper a new approach for indexing biomedical documents based on the possibilistic network, which carries out a partial matching between documents and the MeSH thesaurus (Medical Subject Headings) terms. The main contribution of our approach is to deal with the imprecision and the uncertainty of the indexing task by using the possibility theory. In fact, we propose to enhance the estimation of a document relevance given a concept by using the two measures of possibility and necessity instead of only one measure used by common approaches. The possibility measure estimates the degree of rejection of an irrelevant document given a concept. The necessity of the relevance of a document estimates what extent a document is relevant for a given concept. Our contribution also consists in reducing the limitation of the partial matching that generates irrelevant information although it allows finding in the document other variants of terms than those in the dictionaries. In fact, we propose to filter the index using the knowledge provided by the Unified Medical Language System (UMLS). The filtering allows keeping relevant concepts among those having a subset of their words terms in the document. The experiments carried out at the different steps of our approach and on different corpora showed very encouraging results.",[]
7,53e9b0d1b7602d9703b4d333,ReComment: towards critiquing-based recommendation with speech interaction,"Peter Grasch, Alexander Felfernig, Florian Reinfrank",2013,Graz,"In contrast to search-based approaches, critiquing-based recommender systems provide a navigation-based interface where users are enabled to critique displayed recommendations as a means of preference elicitation. In this paper we present Recomment, our approach to natural language based unit critiquing. We discuss the developed prototype and present the corresponding user interface. In order to show the applicability of our concepts, we present the results of a user study. This study shows that speech interfaces have the potential to improve the perceived ease of use as well as the overall quality of recommendations.","['53e9b290b7602d9703d3507a', '53e9abfeb7602d97035bd4ca', '53e9980eb7602d97020274bb', '53e9b1bcb7602d9703c4bc66', '53e9acefb7602d97036cafa9', '53e9b130b7602d9703baea08', '53e9abf1b7602d97035af167', '53e9987db7602d97020b6b1c', '53e9b3bcb7602d9703ea6f6b', '53e99fd6b7602d97028b2e38', '53e9bd0ab7602d97049909cf', '53e9a95db7602d97032b5dc3', '53e99f8cb7602d970285fa1a', '53e9b715b7602d97042ab04c']"
8,53e99960b7602d97021a3961,Mining triadic closure patterns in social networks,"Hong Huang, Jie Tang, Sen Wu, Lu Liu, Xiaoming fu",2014,WWW (Companion Volume),"A closed triad is a group of three people who are connected with each other. It is the most basic unit for studying group phenomena in social networks. In this paper, we study how closed triads are formed in dynamic networks. More specifically, given three persons, what are the fundamental factors that trigger the formation of triadic closure? There are various factors that may influence the formation of a relationship between persons. Can we design a unified model to predict the formation of triadic closure? Employing a large microblogging network as the source in our study, we formally define the problem and conduct a systematic investigation. The study uncovers how user demographics and network topology influence the process of triadic closure. We also present a probabilistic graphical model to predict whether three persons will form a closed triad in dynamic networks. The experimental results on the microblogging data demonstrate the efficiency of our proposed model for the prediction of triadic closure formation.",[]
9,53e9add4b7602d97037d96ff,Representing documents through their readers,"Khalid El-Arini, Min Xu, Emily B. Fox, Carlos Guestrin",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"From Twitter to Facebook to Reddit, users have become accustomed to sharing the articles they read with friends or followers on their social networks. While previous work has modeled what these shared stories say about the user who shares them, the converse question remains unexplored: what can we learn about an article from the identities of its likely readers? To address this question, we model the content of news articles and blog posts by attributes of the people who are likely to share them. For example, many Twitter users describe themselves in a short profile, labeling themselves with phrases such as ""vegetarian"" or ""liberal."" By assuming that a user's labels correspond to topics in the articles he shares, we can learn a labeled dictionary from a training corpus of articles shared on Twitter. Thereafter, we can code any new document as a sparse non-negative linear combination of user labels, where we encourage correlated labels to appear together in the output via a structured sparsity penalty. Finally, we show that our approach yields a novel document representation that can be effectively used in many problem settings, from recommendation to modeling news dynamics. For example, while the top politics stories will change drastically from one month to the next, the ""politics"" label will still be there to describe them. We evaluate our model on millions of tweeted news articles and blog posts collected between September 2010 and September 2012, demonstrating that our approach is effective.","['53e9983db7602d9702065035', '53e9a099b7602d9702982496', '53e99a92b7602d9702306a53', '53e9afa0b7602d97039ea981', '53e9bac2b7602d97046f111d', '53e9b1eab7602d9703c7e8cb', '53e99bf0b7602d970249b1cb', '53e9b2f0b7602d9703daca71', '53e9b01cb7602d9703a77606', '53e9b600b7602d97041549b7', '53e9ad4eb7602d9703731a83']"
10,53e9b512b7602d9704046035,Linking named entities in Tweets with knowledge base via user interest modeling,"Wei Shen, Jianyong Wang, Ping Luo, Min Wang",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"Twitter has become an increasingly important source of information, with more than 400 million tweets posted per day. The task to link the named entity mentions detected from tweets with the corresponding real world entities in the knowledge base is called tweet entity linking. This task is of practical importance and can facilitate many different tasks, such as personalized recommendation and user interest discovery. The tweet entity linking task is challenging due to the noisy, short, and informal nature of tweets. Previous methods focus on linking entities in Web documents, and largely rely on the context around the entity mention and the topical coherence between entities in the document. However, these methods cannot be effectively applied to the tweet entity linking task due to the insufficient context information contained in a tweet. In this paper, we propose KAURI, a graph-based framework to collectively link all the named entity mentions in all tweets posted by a user via modeling the user's topics of interest. Our assumption is that each user has an underlying topic interest distribution over various named entities. KAURI integrates the intra-tweet local information with the inter-tweet user interest information into a unified graph-based framework. We extensively evaluated the performance of KAURI over manually annotated tweet corpus, and the experimental results show that KAURI significantly outperforms the baseline methods in terms of accuracy, and KAURI is efficient and scales well to tweet stream.","['53e9b991b7602d970457fe44', '53e9ab78b7602d970351a734', '53e9a501b7602d9702e2382a', '53e9b4ceb7602d9703fefa30', '53e9b95bb7602d9704546d3b', '53e9bbdbb7602d970482c288', '53e99b8db7602d9702431ca4', '53e9ad2db7602d970371125c', '53e9a5c5b7602d9702eec0b2', '53e99dbeb7602d970267c0b7', '53e9ab6fb7602d970350f68b', '53e9a21db7602d9702b2470e', '53e9a97bb7602d97032d6176', '53e99884b7602d97020bc30e', '53e9b50ab7602d970403b64f', '53e999f5b7602d970223c4b0', '53e9a06cb7602d970295277c', '53e9aba4b7602d970354e57a']"
11,53e9b2f4b7602d9703db00dd,Text-based measures of document diversity,"Kevin Bache, David Newman, Padhraic Smyth",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"Quantitative notions of diversity have been explored across a variety of disciplines ranging from conservation biology to economics. However, there has been relatively little work on measuring the diversity of text documents via their content. In this paper we present a text-based framework for quantifying how diverse a document is in terms of its content. The proposed approach learns a topic model over a corpus of documents, and computes a distance matrix between pairs of topics using measures such as topic co-occurrence. These pairwise distance measures are then combined with the distribution of topics within a document to estimate each document's diversity relative to the rest of the corpus. The method provides several advantages over existing methods. It is fully data-driven, requiring only the text from a corpus of documents as input, it produces human-readable explanations, and it can be generalized to score diversity of other entities such as authors, academic departments, or journals. We describe experimental results on several large data sets which suggest that the approach is effective and accurate in quantifying how diverse a document is relative to other documents in a corpus.","['53e9ba4ab7602d970466037a', '53e9b35ab7602d9703e38c9c']"
12,53e9bad0b7602d9704701217,Status quo bias in configuration systems,"Monika Mandl, Alexander Felfernig, Juha Tiihonen, Klaus Isak",2011,Graz,"Product configuration systems are an important instrument to implement mass customization, a production paradigm that supports the manufacturing of highly-variant products under pricing conditions similar to mass production. A side-effect of the high diversity of products offered by a configurator is that the complexity of the alternatives may outstrip a user's capability to explore them and make a buying decision. A personalization of such systems through the calculation of feature recommendations (defaults) can support customers (users) in the specification of their requirements and thus can lead to a higher customer satisfaction. A major risk of defaults is that they can cause a status quo bias and therefore make users choose options that are, for example, not really needed to fulfill their requirements. In this paper we present the results of an empirical study that aimed to explore whether there exist status quo effects in product configuration scenarios.","['53e99af7b7602d9702387582', '53e99e30b7602d97026f10f0', '53e9ae90b7602d97038b06b0', '53e9a812b7602d97031555b2', '53e9bc10b7602d9704875345', '53e9a058b7602d970293b0d2', '53e99959b7602d970219834c', '53e9bcc5b7602d9704945fac']"
13,555043af45ce0a409eb48d40,Extraction possibiliste de concepts MeSH à partir de documents biomédicaux.,"Wiem Chebil, Lina Fatima Soualmia, Mohamed N. Omri, Stéfan Jacques Darmoni",2014,Revue d'Intelligence Artificielle,"We propose in this paper a new approach for indexing biomedical documents based on the possibilistic network, which carries out a partial matching between documents and the MeSH thesaurus (Medical Subject Headings) terms. The main contribution of our approach is to deal with the imprecision and the uncertainty of the indexing task by using the possibility theory. In fact, we propose to enhance the estimation of a document relevance given a concept by using the two measures of possibility and necessity instead of only one measure used by common approaches. The possibility measure estimates the degree of rejection of an irrelevant document given a concept. The necessity of the relevance of a document estimates what extent a document is relevant for a given concept. Our contribution also consists in reducing the limitation of the partial matching that generates irrelevant information although it allows finding in the document other variants of terms than those in the dictionaries. In fact, we propose to filter the index using the knowledge provided by the Unified Medical Language System (UMLS). The filtering allows keeping relevant concepts among those having a subset of their words terms in the document. The experiments carried out at the different steps of our approach and on different corpora showed very encouraging results.",[]
14,53e9b44ab7602d9703f424a7,"Group formation in large social networks: membership, growth, and evolution","Lars Backstrom, Dan Huttenlocher, Jon F. Kleinberg, Xiangyang Lan",2006,Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,"The processes by which communities come together, attract new members, and develop over time is a central research issue in the social sciences - political movements, professional organizations, and religious denominations all provide fundamental examples of such communities. In the digital domain, on-line groups are becoming increasingly prominent due to the growth of community and social networking sites such as MySpace and LiveJournal. However, the challenge of collecting and analyzing large-scale time-resolved data on social groups and communities has left most basic questions about the evolution of such groups largely unresolved: what are the structural features that influence whether individuals will join communities, which communities will grow rapidly, and how do the overlaps among pairs of communities change over time.Here we address these questions using two large sources of data: friendship links and community membership on LiveJournal, and co-authorship and conference publications in DBLP. Both of these datasets provide explicit user-defined communities, where conferences serve as proxies for communities in DBLP. We study how the evolution of these communities relates to properties such as the structure of the underlying social networks. We find that the propensity of individuals to join communities, and of communities to grow rapidly, depends in subtle ways on the underlying network structure. For example, the tendency of an individual to join a community is influenced not just by the number of friends he or she has within the community, but also crucially by how those friends are connected to one another. We use decision-tree techniques to identify the most significant structural determinants of these properties. We also develop a novel methodology for measuring movement of individuals between communities, and show how such movements are closely aligned with changes in the topics of interest within the communities.",[]
15,53e9add4b7602d97037d96ff,Representing documents through their readers,"Khalid El-Arini, Min Xu, Emily B. Fox, Carlos Guestrin",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"From Twitter to Facebook to Reddit, users have become accustomed to sharing the articles they read with friends or followers on their social networks. While previous work has modeled what these shared stories say about the user who shares them, the converse question remains unexplored: what can we learn about an article from the identities of its likely readers? To address this question, we model the content of news articles and blog posts by attributes of the people who are likely to share them. For example, many Twitter users describe themselves in a short profile, labeling themselves with phrases such as ""vegetarian"" or ""liberal."" By assuming that a user's labels correspond to topics in the articles he shares, we can learn a labeled dictionary from a training corpus of articles shared on Twitter. Thereafter, we can code any new document as a sparse non-negative linear combination of user labels, where we encourage correlated labels to appear together in the output via a structured sparsity penalty. Finally, we show that our approach yields a novel document representation that can be effectively used in many problem settings, from recommendation to modeling news dynamics. For example, while the top politics stories will change drastically from one month to the next, the ""politics"" label will still be there to describe them. We evaluate our model on millions of tweeted news articles and blog posts collected between September 2010 and September 2012, demonstrating that our approach is effective.",[]
16,53e9a974b7602d97032ce84c,The autonomic operating system research project: achievements and future directions,"Davide B. Bartolini, Riccardo Cattaneo, Gianluca C. Durelli, Martina Maggio, Marco D. Santambrogio, Filippo Sironi",2013,DAC,"Traditionally, hypervisors, operating systems, and runtime systems have been providing an abstraction layer over the bare-metal hardware. Traditional abstractions, however, do not consider for non-functional requirements such as system-level constraints or users' objectives. As these requirements are gaining increasing importance, researchers are looking into making user-specified and system-level objectives first-class citizens in the computer systems' realm. This paper describes the Autonomic Operating System (AcOS) project; AcOS enhances commodity operating systems with an autonomic layer that enables self-* properties through adaptive resource allocation. With AcOS, we investigate intelligent resource allocation to achieve user-specified service-level objectives on application performance and to respect system-level thresholds on CPU temperature. We give a broad overview of AcOS, elaborate on its achievements, and discuss research perspectives.","['53e9b145b7602d9703bca5e5', '53e9b5fab7602d970414ee4b', '53e9afcdb7602d9703a219b1', '53e9b968b7602d970455603f', '53e99b26b7602d97023bf3ad', '53e9bc1bb7602d9704884eee', '53e9a058b7602d970293e3db', '53e9a611b7602d9702f3f498', '53e9b181b7602d9703c0b88e', '53e99d81b7602d970263f8a2', '53e9bd55b7602d97049ecdc7', '53e9ba23b7602d970462c045', '53e9a79eb7602d97030da24f', '53e9a797b7602d97030d6401', '53e9ab1ab7602d97034a0dc9', '53e9b130b7602d9703baff27', '53e99f56b7602d9702824a23', '53e9a5b6b7602d9702edfaff', '53e99b1bb7602d97023ae6f1', '53e99f20b7602d97027ec1de', '53e9b895b7602d9704469c80', '53e9be34b7602d9704aeeae8', '53e9bb53b7602d9704794511']"
17,53e9b715b7602d97042ab04c,Improving the performance of unit critiquing,"Monika Mandl, Alexander Felfernig",2012,Graz,"Conversational recommender systems allow users to learn and adapt their preferences according to concrete examples. Critiquing systems support such a conversational interaction style. Especially unit critiques offer a low cost feedback strategy for users in terms of the needed cognitive effort. In this paper we present an extension of the experience-based unit critiquing algorithm. The development of our new approach, which we call nearest neighbor compatibility critiquing, was aimed at increasing the efficiency of unit critiquing. We combine our new approach with existing critiquing strategies to ensemble-based variations and present the results of an empirical study that aimed at comparing the recommendation efficiency (in terms of the number of critiquing cycles) of ensemble-based solutions with individual critiquing algorithms.","['53e9b290b7602d9703d3507a', '53e9acefb7602d97036cafa9', '53e9bd0ab7602d97049919b7', '53e99fd6b7602d97028b2e38', '53e9bd0ab7602d97049909cf', '53e9a95db7602d97032b5dc3', '53e99f8cb7602d970285fa1a']"
18,53e9a22bb7602d9702b30bca,SAE: social analytic engine for large networks,"Yang Yang, Jianfei Wang, Yutao Zhang, Wei Chen, Jing Zhang, Honglei Zhuang, Zhilin Yang, Bo Ma, Zhanpeng Fang, Sen Wu, Xiaoxiao Li, Debing Liu, Jie Tang",2013,SIGKDD,"Online social networks become a bridge to connect our physical daily life and the virtual Web space, which not only provides rich data for mining, but also brings many new challenges. In this paper, we present a novel Social Analytic Engine (SAE) for large online social networks. The key issues we pursue in the analytic engine are concerned with the following problems: 1) at the micro-level, how do people form different types of social ties and how people influence each other? 2) at the meso-level, how do people group into communities? 3) at the macro-level, what are the hottest topics in a social network and how the topics evolve over time? We propose methods to address the above questions. The methods are general and can be applied to various social networking data. We have deployed and validated the proposed analytic engine over multiple different networks and validated the effectiveness and efficiency of the proposed methods.","['53e9a5afb7602d9702edacce', '53e9b6eeb7602d970427f098', '53e9a10eb7602d97029fb1c4', '53e9bb36b7602d9704775404', '53e99c92b7602d97025467fd', '53e9abebb7602d97035a7132', '53e9b8ccb7602d97044aaf91', '53e9b1cab7602d9703c5e35f', '53e9ba39b7602d9704647974', '53e9ad9eb7602d9703798263']"
19,53e9ac42b7602d9703610647,Explore person specific evidence in web person name disambiguation,"Liwei Chen, Yansong Feng, Lei Zou, Dongyan Zhao",2012,EMNLP-CoNLL,"In this paper, we investigate different usages of feature representations in the web person name disambiguation task which has been suffering from the mismatch of vocabulary and lack of clues in web environments. In literature, the latter receives less attention and remains more challenging. We explore the feature space in this task and argue that collecting person specific evidences from a corpus level can provide a more reasonable and robust estimation for evaluating a feature's importance in a given web page. This can alleviate the lack of clues where discriminative features can be reasonably weighted by taking their corpus level importance into account, not just relying on the current local context. We therefore propose a topic-based model to exploit the person specific global importance and embed it into the person name similarity. The experimental results show that the corpus level topic information provides more stable evidences for discriminative features and our method outperforms the state-of-the-art systems on three WePS datasets.","['53e9b6a2b7602d97042188c9', '53e99af7b7602d97023857f1', '53e9aec4b7602d97038edc3b', '53e998a3b7602d97020df1f6', '53e9a63db7602d9702f6a8fa', '53e9a825b7602d970316d97c', '53e9bad7b7602d97047061c9', '53e9b85bb7602d9704421d74', '53e9aa87b7602d9703400792', '53e9b316b7602d9703de00be', '53e9a540b7602d9702e63783', '53e9a6b4b7602d9702fe58fa']"
20,53e9add4b7602d97037d96ff,Representing documents through their readers,"Khalid El-Arini, Min Xu, Emily B. Fox, Carlos Guestrin",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"From Twitter to Facebook to Reddit, users have become accustomed to sharing the articles they read with friends or followers on their social networks. While previous work has modeled what these shared stories say about the user who shares them, the converse question remains unexplored: what can we learn about an article from the identities of its likely readers? To address this question, we model the content of news articles and blog posts by attributes of the people who are likely to share them. For example, many Twitter users describe themselves in a short profile, labeling themselves with phrases such as ""vegetarian"" or ""liberal."" By assuming that a user's labels correspond to topics in the articles he shares, we can learn a labeled dictionary from a training corpus of articles shared on Twitter. Thereafter, we can code any new document as a sparse non-negative linear combination of user labels, where we encourage correlated labels to appear together in the output via a structured sparsity penalty. Finally, we show that our approach yields a novel document representation that can be effectively used in many problem settings, from recommendation to modeling news dynamics. For example, while the top politics stories will change drastically from one month to the next, the ""politics"" label will still be there to describe them. We evaluate our model on millions of tweeted news articles and blog posts collected between September 2010 and September 2012, demonstrating that our approach is effective.",[]
21,53e9ab9eb7602d970354ab1a,TurboGraph: a fast parallel graph engine handling billion-scale graphs in a single PC,"Wook-Shin Han, Sangyeon Lee, Kyungyeol Park, Jeong-Hoon Lee, Min-Soo Kim, Jinha Kim, Hwanjo Yu",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"Graphs are used to model many real objects such as social networks and web graphs. Many real applications in various fields require efficient and effective management of large-scale graph structured data. Although distributed graph engines such as GBase and Pregel handle billion-scale graphs, the user needs to be skilled at managing and tuning a distributed system in a cluster, which is a nontrivial job for the ordinary user. Furthermore, these distributed systems need many machines in a cluster in order to provide reasonable performance. In order to address this problem, a disk-based parallel graph engine called Graph-Chi, has been recently proposed. Although Graph-Chi significantly outperforms all representative (disk-based) distributed graph engines, we observe that Graph-Chi still has serious performance problems for many important types of graph queries due to 1) limited parallelism and 2) separate steps for I/O processing and CPU processing. In this paper, we propose a general, disk-based graph engine called TurboGraph to process billion-scale graphs very efficiently by using modern hardware on a single PC. TurboGraph is the first truly parallel graph engine that exploits 1) full parallelism including multi-core parallelism and FlashSSD IO parallelism and 2) full overlap of CPU processing and I/O processing as much as possible. Specifically, we propose a novel parallel execution model, called pin-and-slide. TurboGraph also provides engine-level operators such as BFS which are implemented under the pin-and-slide model. Extensive experimental results with large real datasets show that TurboGraph consistently and significantly outperforms Graph-Chi by up to four orders of magnitude! Our implementation of TurboGraph is available at ``http://wshan.net/turbograph}"" as executable files.","['53e99baab7602d9702453aba', '53e9aa09b7602d97033759bb', '53e9b44ab7602d9703f424a7', '53e9a65fb7602d9702f8eb17', '53e9a45cb7602d9702d783b7', '53e9b7f5b7602d97043a7d34', '53e99f0ab7602d97027da071', '53e9a433b7602d9702d5162e', '53e9a36db7602d9702c78a53', '53e9bd38b7602d97049c6cbd', '53e9b38fb7602d9703e710a2', '53e9a455b7602d9702d70953', '53e9ad4eb7602d9703731a83', '53e9a7bab7602d97030f469f', '53e9bb1db7602d970475ac85', '53e9b108b7602d9703b8369d']"
22,53e9add4b7602d97037d96ff,Representing documents through their readers,"Khalid El-Arini, Min Xu, Emily B. Fox, Carlos Guestrin",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"From Twitter to Facebook to Reddit, users have become accustomed to sharing the articles they read with friends or followers on their social networks. While previous work has modeled what these shared stories say about the user who shares them, the converse question remains unexplored: what can we learn about an article from the identities of its likely readers? To address this question, we model the content of news articles and blog posts by attributes of the people who are likely to share them. For example, many Twitter users describe themselves in a short profile, labeling themselves with phrases such as ""vegetarian"" or ""liberal."" By assuming that a user's labels correspond to topics in the articles he shares, we can learn a labeled dictionary from a training corpus of articles shared on Twitter. Thereafter, we can code any new document as a sparse non-negative linear combination of user labels, where we encourage correlated labels to appear together in the output via a structured sparsity penalty. Finally, we show that our approach yields a novel document representation that can be effectively used in many problem settings, from recommendation to modeling news dynamics. For example, while the top politics stories will change drastically from one month to the next, the ""politics"" label will still be there to describe them. We evaluate our model on millions of tweeted news articles and blog posts collected between September 2010 and September 2012, demonstrating that our approach is effective.",[]
23,53e9a4b2b7602d9702dd46bc,Graph similarity search with edit distance constraint in large graph databases,"Weiguo Zheng, Lei Zou, Xiang Lian, Dong Wang, Dongyan Zhao",2013,CIKM,"Due to many real applications of graph databases, it has become increasingly important to retrieve graphs g (in graph database D) that approximately match with query graph q, rather than exact subgraph matches. In this paper, we study the problem of graph similarity search, which retrieves graphs that are similar to a given query graph under the constraint of the minimum edit distance. Specifically, we derive a lower bound, branch-based bound, which can greatly reduce the search space of the graph similarity search. We also propose a tree index structure, namely b-tree, to facilitate effective pruning and efficient query processing. Extensive experiments confirm that our proposed approach outperforms the existing approaches by orders of magnitude, in terms of both pruning power and query response time.","['53e9bd31b7602d97049bf4a2', '53e9a289b7602d9702b8bdc4', '53e9bc2db7602d970489aa33', '53e9b1c9b7602d9703c57231', '53e99a7fb7602d97022f0d16', '53e9a107b7602d97029f1d43', '53e9a123b7602d9702a1494c', '53e9afb3b7602d97039ff004', '53e99924b7602d970215c422', '53e9a433b7602d9702d5162e', '53e9b276b7602d9703d1b9ba', '53e9adbdb7602d97037c18e4', '53e9b6d0b7602d970425bd8d', '53e9ae97b7602d97038bb315']"
24,53e9afc7b7602d9703a1abc6,Estimating sharer reputation via social data calibration,"Jaewon Yang, Bee-Chung Chen, Deepak Agarwal",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"Online social networks have become important channels for users to share content with their connections and diffuse information. Although much work has been done to identify socially influential users, the problem of finding ""reputable"" sharers, who share good content, has received relatively little attention. Availability of such reputation scores can be useful or various applications like recommending people to follow, procuring high quality content in a scalable way, creating a content reputation economy to incentivize high quality sharing, and many more. To estimate sharer reputation, it is intuitive to leverage data that records how recipients respond (through clicking, liking, etc.) to content items shared by a sharer. However, such data is usually biased --- it has a selection bias since the shared items can only be seen and responded to by users connected to the sharer in most social networks, and it has a response bias since the response is usually influenced by the relationship between the sharer and the recipient (which may not indicate whether the shared content is good). To correct for such biases, we propose to utilize an additional data source that provides unbiased goodness estimates for a small set of shared items, and calibrate biased social data through a novel multi-level hierarchical model that describes how the unbiased data and biased data are jointly generated according to sharer reputation scores. The unbiased data also provides the ground truth for quantitative evaluation of different methods. Experiments based on such ground-truth data show that our proposed model significantly outperforms existing methods that estimate social influence using biased social data.","['53e9a9d3b7602d97033335eb', '53e9bb1cb7602d97047562b9', '53e9b6d1b7602d970425d749', '53e9bb5ab7602d970479b4ad', '53e9b57cb7602d97040bdd6d', '53e9a7bab7602d97030f7013', '53e9b4ceb7602d9703fefa30', '53e9bb36b7602d9704775404', '53e9bb7fb7602d97047c31d4', '53e9b666b7602d97041ca191', '53e9bc80b7602d9704900b79', '53e99960b7602d970219efd7', '53e9a7d5b7602d9703111de1', '53e9a4f3b7602d9702e14ec3', '53e9afeeb7602d9703a42f36', '53e99937b7602d9702172d40', '53e9b600b7602d97041549b7', '53e9a46bb7602d9702d8b349', '53e9a7d6b7602d9703117616', '53e9b08ab7602d9703af740a', '53e99afdb7602d970238a9d8', '53e9a186b7602d9702a77a8a', '53e9a914b7602d9703269433', '53e99b8db7602d9702431772']"
25,53e9a812b7602d9703156ee8,Confluence: conformity influence in large social networks,"Jie Tang, Sen Wu, Jimeng Sun",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"Conformity is a type of social influence involving a change in opinion or behavior in order to fit in with a group. Employing several social networks as the source for our experimental data, we study how the effect of conformity plays a role in changing users' online behavior. We formally define several major types of conformity in individual, peer, and group levels. We propose Confluence model to formalize the effects of social conformity into a probabilistic model. Confluence can distinguish and quantify the effects of the different types of conformities. To scale up to large social networks, we propose a distributed learning method that can construct the Confluence model efficiently with near-linear speedup. Our experimental results on four different types of large social networks, i.e., Flickr, Gowalla, Weibo and Co-Author, verify the existence of the conformity phenomena. Leveraging the conformity information, Confluence can accurately predict actions of users. Our experiments show that Confluence significantly improves the prediction accuracy by up to 5-10% compared with several alternative methods.","['53e9a37ab7602d9702c883ee', '53e99d0bb7602d97025bde89', '53e9bb15b7602d9704750d5a', '53e9b6d1b7602d970425d749', '53e9bafbb7602d9704733fb6', '53e9af46b7602d97039828ad', '53e9bb5ab7602d970479b4ad', '53e9a5afb7602d9702edacce', '53e9b6eeb7602d970427f098', '53e9996fb7602d97021b3239', '53e9a114b7602d9702a03f7a', '53e9a301b7602d9702c0a131', '53e9ad72b7602d970375da90', '53e9b7d3b7602d97043837ca', '53e9ba54b7602d9704669afc', '53e99f8db7602d970286525f', '53e9b655b7602d97041b58f9', '53e9a58cb7602d9702eb7f75', '53e9bb7fb7602d97047c36b9', '53e9b8ccb7602d97044aaf91', '53e997dcb7602d9701fd0d1d', '53e9985fb7602d9702098a11', '53e9ad9eb7602d9703798263']"
26,53e9add4b7602d97037d96ff,Representing documents through their readers,"Khalid El-Arini, Min Xu, Emily B. Fox, Carlos Guestrin",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"From Twitter to Facebook to Reddit, users have become accustomed to sharing the articles they read with friends or followers on their social networks. While previous work has modeled what these shared stories say about the user who shares them, the converse question remains unexplored: what can we learn about an article from the identities of its likely readers? To address this question, we model the content of news articles and blog posts by attributes of the people who are likely to share them. For example, many Twitter users describe themselves in a short profile, labeling themselves with phrases such as ""vegetarian"" or ""liberal."" By assuming that a user's labels correspond to topics in the articles he shares, we can learn a labeled dictionary from a training corpus of articles shared on Twitter. Thereafter, we can code any new document as a sparse non-negative linear combination of user labels, where we encourage correlated labels to appear together in the output via a structured sparsity penalty. Finally, we show that our approach yields a novel document representation that can be effectively used in many problem settings, from recommendation to modeling news dynamics. For example, while the top politics stories will change drastically from one month to the next, the ""politics"" label will still be there to describe them. We evaluate our model on millions of tweeted news articles and blog posts collected between September 2010 and September 2012, demonstrating that our approach is effective.",[]
27,53e9aa23b7602d970338f333,Collaborative topic modeling for recommending scientific articles,"Chong Wang, David M. Blei",2011,Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,"Researchers have access to large online archives of scientific articles. As a consequence, finding relevant papers has become more difficult. Newly formed online communities of researchers sharing citations provides a new way to solve this problem. In this paper, we develop an algorithm to recommend scientific articles to users of an online community. Our approach combines the merits of traditional collaborative filtering and probabilistic topic modeling. It provides an interpretable latent structure for users and items, and can form recommendations about both existing and newly published articles. We study a large subset of data from CiteULike, a bibliography sharing service, and show that our algorithm provides a more effective recommender system than traditional collaborative filtering.","['53e99dfeb7602d97026c0a21', '53e9a7c0b7602d97030fc25a', '53e9bc2cb7602d9704897c4f', '53e9983db7602d9702065035', '53e9a54eb7602d9702e73fa6', '53e9a2d5b7602d9702bdc5ae', '53e99a73b7602d97022e10a2', '53e9af2db7602d970396ad89', '53e9addbb7602d97037e40df', '53e9a636b7602d9702f66092', '53e9b6f4b7602d970428ac2d', '53e9a4cfb7602d9702def47d']"
28,53e9a5d3b7602d9702efe6d6,ReAction: personalized minimal repair adaptations for customer requests,"Monika Schubert, Alexander Felfernig, Florian Reinfrank",2011,Graz,"Knowledge-based recommender systems support users in finding interesting products from large and potentially complex product assortments. In such systems users continuously refine their specifications which the product has to satisfy. If the specifications are too narrow no product can be retrieved from the product assortment. Instead of just notifying the customer that no product could be found we introduce an approach called ReAction to support customers with minimal repair adaptations. In this paper we give a detailed explanation of our algorithm. Besides that we present the results of a detailed empirical evaluation focussing on the quality as well as on the runtime performance. The work presented is relevant for designers and developers of database systems as well as knowledge-based recommender systems interested in (i) identifying relaxations for database queries, (ii) applying and dealing with user utilities, and (iii) improving the system usability through suggesting minimal repair adaptations for inconsistent queries.","['53e99813b7602d970202d631', '53e9bbcfb7602d970481e7f2', '53e9a2b2b7602d9702bba4e2', '53e999ffb7602d970224a173', '53e9bb94b7602d97047de6d3', '53e9ad04b7602d97036e3240', '53e99813b7602d970202dfb3', '53e9a95eb7602d97032b9dd8', '53e9a667b7602d9702f9a5b9', '53e99ffcb7602d97028df299']"
29,53e9bab4b7602d97046e48fb,Social influence locality for modeling retweeting behaviors,"Jing Zhang, Biao Liu, Jie Tang, Ting Chen, Juanzi Li",2013,IJCAI,"We study an interesting phenomenon of social influence locality in a large microblogging network, which suggests that users' behaviors are mainly influenced by close friends in their ego networks. We provide a formal definition for the notion of social influence locality and develop two instantiation functions based on pairwise influence and structural diversity. The defined influence locality functions have strong predictive power. Without any additional features, we can obtain a F1-score of 71.65% for predicting users' retweet behaviors by training a logistic regression classifier based on the defined functions. Our analysis also reveals several intriguing discoveries. For example, though the probability of a user retweeting a microblog is positively correlated with the number of friends who have retweeted the microblog, it is surprisingly negatively correlated with the number of connected circles that are formed by those friends.","['53e9b6d1b7602d970425d749', '53e9b8cdb7602d97044ae570', '53e99ca0b7602d970254f819', '53e9b6eeb7602d970427f098', '53e9a114b7602d9702a03f7a', '53e9a36db7602d9702c7a3fd', '53e9b991b7602d970458168f', '53e9b2d7b7602d9703d88558', '53e9a71fb7602d970305312a', '53e99d7ab7602d97026343dc', '53e999f5b7602d970223c4b0']"
30,53e9add4b7602d97037d96ff,Representing documents through their readers,"Khalid El-Arini, Min Xu, Emily B. Fox, Carlos Guestrin",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"From Twitter to Facebook to Reddit, users have become accustomed to sharing the articles they read with friends or followers on their social networks. While previous work has modeled what these shared stories say about the user who shares them, the converse question remains unexplored: what can we learn about an article from the identities of its likely readers? To address this question, we model the content of news articles and blog posts by attributes of the people who are likely to share them. For example, many Twitter users describe themselves in a short profile, labeling themselves with phrases such as ""vegetarian"" or ""liberal."" By assuming that a user's labels correspond to topics in the articles he shares, we can learn a labeled dictionary from a training corpus of articles shared on Twitter. Thereafter, we can code any new document as a sparse non-negative linear combination of user labels, where we encourage correlated labels to appear together in the output via a structured sparsity penalty. Finally, we show that our approach yields a novel document representation that can be effectively used in many problem settings, from recommendation to modeling news dynamics. For example, while the top politics stories will change drastically from one month to the next, the ""politics"" label will still be there to describe them. We evaluate our model on millions of tweeted news articles and blog posts collected between September 2010 and September 2012, demonstrating that our approach is effective.",[]
31,554269b045ce2eec0b916065,Enriching Semantically Web Service Descriptions.,"Maricela Bravo, José Rodríguez, José A. Reyes",2014,OTM Conferences,"Service Oriented Computing (SOC) has incrementally been adopted as the preferred programming paradigm for the development, integration and interoperation of large and complex information systems. However , despite its increasing popularity, the SOC has not achieved its full potential yet. This is mainly due to the lack of supporting tools to enrich and represent semantically Web service descriptions. This paper describes a solution approach for the automatic representation of Web service descriptions and their further semantic enrichment between operation names based on the calculation of four semantic similarity measures. The enrichment approach is accurate because the final decision is done through a voting scheme, in the case of inconsistent results, these are not asserted into the ontology. Experimentation shows that although few similarity relationships are found and asserted , they represent an important step towards the automatic discovery of information that was previously unknown.",[]
32,53e9b0a5b7602d9703b11186,Connecting users across social media sites: a behavioral-modeling approach,"Reza Zafarani, Huan Liu",2013,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,"People use various social media for different purposes. The information on an individual site is often incomplete. When sources of complementary information are integrated, a better profile of a user can be built to improve online services such as verifying online information. To integrate these sources of information, it is necessary to identify individuals across social media sites. This paper aims to address the cross-media user identification problem. We introduce a methodology (MOBIUS) for finding a mapping among identities of individuals across social media sites. It consists of three key components: the first component identifies users' unique behavioral patterns that lead to information redundancies across sites; the second component constructs features that exploit information redundancies due to these behavioral patterns; and the third component employs machine learning for effective user identification. We formally define the cross-media user identification problem and show that MOBIUS is effective in identifying users across social media sites. This study paves the way for analysis and mining across social media sites, and facilitates the creation of novel online services across sites.",[]
33,55465ea10cf2939c2feebd0d,Improving Multi-Objective Test Case Selection by Injecting Diversity in Genetic Algorithms.,"Annibale Panichella, Rocco Oliveto, Massimiliano Di Penta, Andrea De Lucia",2015,IEEE Trans. Software Eng.,"A way to reduce the cost of regression testing consists of selecting or prioritizing subsets of test cases from a test suite according to some criteria. Besides greedy algorithms, cost cognizant additional greedy algorithms, multi-objective optimization algorithms, and multi-objective genetic algorithms (MOGAs), have also been proposed to tackle this problem. However, previous studies have shown that there is no clear winner between greedy and MOGAs, and that their combination does not necessarily produce better results. In this paper we show that the optimality of MOGAs can be significantly improved by diversifying the solutions (sub-sets of the test suite) generated during the search process. Specifically, we introduce a new MOGA, coined as DIversity based Genetic Algorithm (DIV-GA), based on the mechanisms of orthogonal design and orthogonal evolution that increase diversity by injecting new orthogonal individuals during the search process. Results of an empirical study conducted on eleven programs show that DIV-GA outperforms both greedy algorithms and the traditional MOGAs from the optimality point of view. Moreover, the solutions (sub-sets of the test suite) provided by DIV-GA are able to detect more faults than the other algorithms, while keeping the same test execution cost",[]
34,53e9bc00b7602d970485d464,A novel spectral coding in a large graph database,"Lei Zou, Lei Chen, Jeffrey Xu Yu, Yansheng Lu",2008,EDBT,"Retrieving related graphs containing a query graph from a large graph database is a key issue in many graph-based applications, such as drug discovery and structural pattern recognition. Because sub-graph isomorphism is a NP-complete problem [4], we have to employ a filter-and-verification framework to speed up the search efficiency, that is, using an effective and efficient pruning strategy to filter out the false positives (graphs that are not possible in the results) as many as possible first, then validating the remaining candidates by subgraph isomorphism checking. In this paper, we propose a novel filtering method, a spectral encoding method, i.e. GCoding. Specifically, we assign a signature to each vertex based on its local structures. Then, we generate a spectral graph code by combining all vertex signatures in a graph. Based on spectral graph codes, we derive a necessary condition for sub-graph isomorphism. Then we propose two pruning rules for sub-graph search problem, and prove that they satisfy the no-false-negative requirement (no dismissal in answers). Since graph codes are in numerical space, we take this advantage and conduct efficient filtering over graph codes. Extensive experiments show that GCoding outperforms existing counterpart methods.","['53e9a53ab7602d9702e5fac3', '53e9ab20b7602d97034a5cac', '53e9b130b7602d9703bb1fb8', '53e9b11cb7602d9703b9915a', '53e9be35b7602d9704af1ca3', '53e99803b7602d97020146b7', '53e9bb8db7602d97047d603b', '53e9b1c9b7602d9703c57231', '53e9b310b7602d9703dd70d4', '53e9a9d8b7602d9703336db6', '53e9ac7bb7602d970364ff4e', '53e9a011b7602d97028f5b5b']"
